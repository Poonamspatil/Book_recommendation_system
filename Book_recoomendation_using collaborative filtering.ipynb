{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates utilizing different memory based and model based collaborative filtering technique for Book Recommendation. Book recommendations are generated for userid 1839 using four different methods.\n",
    "\n",
    "The 4 methods used for book recommendation are as follows:\n",
    "1. Memory-Based Collaborative filtering\n",
    "    \n",
    "    a. User-based with Eucledean Distance measure\n",
    "    \n",
    "    b. Item-based with Cosine Similarity measure\n",
    "\n",
    "\n",
    "2. Model-based Collaborative filtering\n",
    "    \n",
    "    a. Matrix Factorization\n",
    "    \n",
    "    b. SVD++\n",
    "\n",
    "Original data source can be found [here](https://github.com/zygmuntz/goodbooks-10k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "books = pd.read_csv('books.csv') # Book metadata\n",
    "ratings_data = pd.read_csv('ratings.csv') # User ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>...</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2657</td>\n",
       "      <td>2657</td>\n",
       "      <td>3275794</td>\n",
       "      <td>487</td>\n",
       "      <td>61120081</td>\n",
       "      <td>9.780061e+12</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>...</td>\n",
       "      <td>3198671</td>\n",
       "      <td>3340896</td>\n",
       "      <td>72586</td>\n",
       "      <td>60427</td>\n",
       "      <td>117415</td>\n",
       "      <td>446835</td>\n",
       "      <td>1001952</td>\n",
       "      <td>1714267</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4671</td>\n",
       "      <td>4671</td>\n",
       "      <td>245494</td>\n",
       "      <td>1356</td>\n",
       "      <td>743273567</td>\n",
       "      <td>9.780743e+12</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>...</td>\n",
       "      <td>2683664</td>\n",
       "      <td>2773745</td>\n",
       "      <td>51992</td>\n",
       "      <td>86236</td>\n",
       "      <td>197621</td>\n",
       "      <td>606158</td>\n",
       "      <td>936012</td>\n",
       "      <td>947718</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
       "0        1            2767052       2767052  2792775          272  439023483   \n",
       "1        2                  3             3  4640799          491  439554934   \n",
       "2        3              41865         41865  3212258          226  316015849   \n",
       "3        4               2657          2657  3275794          487   61120081   \n",
       "4        5               4671          4671   245494         1356  743273567   \n",
       "\n",
       "         isbn13                      authors  original_publication_year  \\\n",
       "0  9.780439e+12              Suzanne Collins                     2008.0   \n",
       "1  9.780440e+12  J.K. Rowling, Mary GrandPré                     1997.0   \n",
       "2  9.780316e+12              Stephenie Meyer                     2005.0   \n",
       "3  9.780061e+12                   Harper Lee                     1960.0   \n",
       "4  9.780743e+12          F. Scott Fitzgerald                     1925.0   \n",
       "\n",
       "                             original_title  ... ratings_count  \\\n",
       "0                          The Hunger Games  ...       4780653   \n",
       "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
       "2                                  Twilight  ...       3866839   \n",
       "3                     To Kill a Mockingbird  ...       3198671   \n",
       "4                          The Great Gatsby  ...       2683664   \n",
       "\n",
       "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "0            4942365                   155254      66715     127936   \n",
       "1            4800065                    75867      75504     101676   \n",
       "2            3916824                    95009     456191     436802   \n",
       "3            3340896                    72586      60427     117415   \n",
       "4            2773745                    51992      86236     197621   \n",
       "\n",
       "   ratings_3  ratings_4  ratings_5  \\\n",
       "0     560092    1481305    2706317   \n",
       "1     455024    1156318    3011543   \n",
       "2     793319     875073    1355439   \n",
       "3     446835    1001952    1714267   \n",
       "4     606158     936012     947718   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "3  https://images.gr-assets.com/books/1361975680m...   \n",
       "4  https://images.gr-assets.com/books/1490528560m...   \n",
       "\n",
       "                                     small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s...  \n",
       "1  https://images.gr-assets.com/books/1474154022s...  \n",
       "2  https://images.gr-assets.com/books/1361039443s...  \n",
       "3  https://images.gr-assets.com/books/1361975680s...  \n",
       "4  https://images.gr-assets.com/books/1490528560s...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show you what the data looks like\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to perform some preprocessing of the data. In particular, we will format the ratings data into the nice matrix. We will first merge the two files, so we will eliminate any ratings that does have book metadata information (if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datasets\n",
    "merged_data = pd.merge(books, ratings_data, on='book_id')[['user_id', 'book_id', 'rating', 'original_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null value rows\n",
    "merged_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>original_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2886</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hunger Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6158</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hunger Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3991</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The Hunger Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5281</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hunger Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5721</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hunger Games</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating    original_title\n",
       "0     2886        1       5  The Hunger Games\n",
       "1     6158        1       5  The Hunger Games\n",
       "2     3991        1       4  The Hunger Games\n",
       "3     5281        1       5  The Hunger Games\n",
       "4     5721        1       5  The Hunger Games"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that if we work with this data, we might run into memory issue. Hence I am going to keep only the user with ID less than or equal to 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data[merged_data.user_id <= 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First create the rating matrix. Replace any missing values with 0 afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only required columns to create rating matrix\n",
    "merged_rating = merged_data[['user_id','book_id', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rating matrix using pivot table\n",
    "ratings = merged_rating.pivot_table(index = 'user_id', columns = 'book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove level(s) in row\n",
    "ratings.columns = ratings.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>book_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "book_id  1      2      3      4      5      6      7      8      9      10     \\\n",
       "user_id                                                                         \n",
       "1          NaN    NaN    NaN    5.0    NaN    NaN    NaN    NaN    NaN    4.0   \n",
       "2          NaN    5.0    NaN    NaN    5.0    NaN    NaN    4.0    NaN    5.0   \n",
       "3          NaN    NaN    NaN    3.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4          NaN    5.0    NaN    4.0    4.0    NaN    4.0    4.0    NaN    5.0   \n",
       "5          NaN    NaN    NaN    NaN    NaN    4.0    NaN    NaN    NaN    NaN   \n",
       "\n",
       "book_id  ...  9991   9992   9993   9994   9995   9996   9997   9998   9999   \\\n",
       "user_id  ...                                                                  \n",
       "1        ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2        ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3        ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4        ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "5        ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "book_id  10000  \n",
       "user_id         \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5          NaN  \n",
       "\n",
       "[5 rows x 9391 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with 0\n",
    "ratings.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a. User-Based Collaborative Filtering\n",
    "The first model to use will be the user-based collaborative filtering.\n",
    "\n",
    "1. We will use Euclidean distance to measure the similarity between users (Euclidean distance simply to explore).\n",
    "2. Use 100 neighbors when calculating the predicted scores.\n",
    "3. Get the top 15 recommendations for user with user_id 1839. Get the book titles and predicted ratings.\n",
    "4. Also we'll store the recommendations in a variable. We will compare this result with other models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate user dissimilarity using euclidean distance\n",
    "user_dis_sim = euclidean_distances(ratings)\n",
    "user_dis_sim = pd.DataFrame(user_dis_sim, index = ratings.index, columns = ratings.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.137071</td>\n",
       "      <td>42.320208</td>\n",
       "      <td>52.488094</td>\n",
       "      <td>56.062465</td>\n",
       "      <td>55.569776</td>\n",
       "      <td>61.375891</td>\n",
       "      <td>50.774009</td>\n",
       "      <td>51.672043</td>\n",
       "      <td>51.691392</td>\n",
       "      <td>...</td>\n",
       "      <td>51.146847</td>\n",
       "      <td>53.646994</td>\n",
       "      <td>51.097945</td>\n",
       "      <td>51.526692</td>\n",
       "      <td>72.083285</td>\n",
       "      <td>48.238988</td>\n",
       "      <td>51.971146</td>\n",
       "      <td>49.719212</td>\n",
       "      <td>52.201533</td>\n",
       "      <td>50.783856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.137071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.724048</td>\n",
       "      <td>51.322510</td>\n",
       "      <td>54.074023</td>\n",
       "      <td>54.064776</td>\n",
       "      <td>59.615434</td>\n",
       "      <td>50.009999</td>\n",
       "      <td>50.586559</td>\n",
       "      <td>53.544374</td>\n",
       "      <td>...</td>\n",
       "      <td>48.548944</td>\n",
       "      <td>53.357286</td>\n",
       "      <td>50.695167</td>\n",
       "      <td>52.191953</td>\n",
       "      <td>68.694978</td>\n",
       "      <td>45.365185</td>\n",
       "      <td>49.091751</td>\n",
       "      <td>48.836462</td>\n",
       "      <td>52.668776</td>\n",
       "      <td>47.391982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.320208</td>\n",
       "      <td>39.724048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.583259</td>\n",
       "      <td>44.407207</td>\n",
       "      <td>45.044423</td>\n",
       "      <td>50.970580</td>\n",
       "      <td>39.560081</td>\n",
       "      <td>44.034078</td>\n",
       "      <td>46.292548</td>\n",
       "      <td>...</td>\n",
       "      <td>38.483763</td>\n",
       "      <td>45.066617</td>\n",
       "      <td>42.520583</td>\n",
       "      <td>43.081318</td>\n",
       "      <td>64.319515</td>\n",
       "      <td>34.899857</td>\n",
       "      <td>44.429720</td>\n",
       "      <td>43.714986</td>\n",
       "      <td>44.158804</td>\n",
       "      <td>42.449971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.488094</td>\n",
       "      <td>51.322510</td>\n",
       "      <td>46.583259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.365553</td>\n",
       "      <td>60.024995</td>\n",
       "      <td>61.595454</td>\n",
       "      <td>54.083269</td>\n",
       "      <td>54.046276</td>\n",
       "      <td>56.648036</td>\n",
       "      <td>...</td>\n",
       "      <td>55.560778</td>\n",
       "      <td>58.420887</td>\n",
       "      <td>55.371473</td>\n",
       "      <td>57.166424</td>\n",
       "      <td>72.020830</td>\n",
       "      <td>51.923020</td>\n",
       "      <td>48.207883</td>\n",
       "      <td>51.312766</td>\n",
       "      <td>57.271284</td>\n",
       "      <td>49.879856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56.062465</td>\n",
       "      <td>54.074023</td>\n",
       "      <td>44.407207</td>\n",
       "      <td>60.365553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.111961</td>\n",
       "      <td>63.324561</td>\n",
       "      <td>54.726593</td>\n",
       "      <td>57.766772</td>\n",
       "      <td>59.489495</td>\n",
       "      <td>...</td>\n",
       "      <td>52.678269</td>\n",
       "      <td>57.280014</td>\n",
       "      <td>56.780278</td>\n",
       "      <td>56.089215</td>\n",
       "      <td>72.849159</td>\n",
       "      <td>50.497525</td>\n",
       "      <td>58.395205</td>\n",
       "      <td>57.818682</td>\n",
       "      <td>57.428216</td>\n",
       "      <td>57.567352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id      1          2          3          4          5          6      \\\n",
       "user_id                                                                     \n",
       "1         0.000000  51.137071  42.320208  52.488094  56.062465  55.569776   \n",
       "2        51.137071   0.000000  39.724048  51.322510  54.074023  54.064776   \n",
       "3        42.320208  39.724048   0.000000  46.583259  44.407207  45.044423   \n",
       "4        52.488094  51.322510  46.583259   0.000000  60.365553  60.024995   \n",
       "5        56.062465  54.074023  44.407207  60.365553   0.000000  58.111961   \n",
       "\n",
       "user_id      7          8          9          10     ...      9991   \\\n",
       "user_id                                              ...              \n",
       "1        61.375891  50.774009  51.672043  51.691392  ...  51.146847   \n",
       "2        59.615434  50.009999  50.586559  53.544374  ...  48.548944   \n",
       "3        50.970580  39.560081  44.034078  46.292548  ...  38.483763   \n",
       "4        61.595454  54.083269  54.046276  56.648036  ...  55.560778   \n",
       "5        63.324561  54.726593  57.766772  59.489495  ...  52.678269   \n",
       "\n",
       "user_id      9992       9993       9994       9995       9996       9997   \\\n",
       "user_id                                                                     \n",
       "1        53.646994  51.097945  51.526692  72.083285  48.238988  51.971146   \n",
       "2        53.357286  50.695167  52.191953  68.694978  45.365185  49.091751   \n",
       "3        45.066617  42.520583  43.081318  64.319515  34.899857  44.429720   \n",
       "4        58.420887  55.371473  57.166424  72.020830  51.923020  48.207883   \n",
       "5        57.280014  56.780278  56.089215  72.849159  50.497525  58.395205   \n",
       "\n",
       "user_id      9998       9999       10000  \n",
       "user_id                                   \n",
       "1        49.719212  52.201533  50.783856  \n",
       "2        48.836462  52.668776  47.391982  \n",
       "3        43.714986  44.158804  42.449971  \n",
       "4        51.312766  57.271284  49.879856  \n",
       "5        57.818682  57.428216  57.567352  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_dis_sim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate simialrity matrix between users based on euclidean distance between them by using the formula, similarity = 1/(1+ d(u1,u2) )\n",
    "\n",
    "And with this similarity value ranges between 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate user similarities from euclidean distance matrix\n",
    "user_sim = 1/(1+user_dis_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019180</td>\n",
       "      <td>0.023084</td>\n",
       "      <td>0.018696</td>\n",
       "      <td>0.017525</td>\n",
       "      <td>0.017677</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>0.019315</td>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019177</td>\n",
       "      <td>0.018299</td>\n",
       "      <td>0.019195</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>0.020309</td>\n",
       "      <td>0.018878</td>\n",
       "      <td>0.019716</td>\n",
       "      <td>0.018796</td>\n",
       "      <td>0.019311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024556</td>\n",
       "      <td>0.019112</td>\n",
       "      <td>0.018157</td>\n",
       "      <td>0.018160</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>0.019604</td>\n",
       "      <td>0.019385</td>\n",
       "      <td>0.018334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020182</td>\n",
       "      <td>0.018397</td>\n",
       "      <td>0.019344</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.014348</td>\n",
       "      <td>0.021568</td>\n",
       "      <td>0.019963</td>\n",
       "      <td>0.020066</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>0.020665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023084</td>\n",
       "      <td>0.024556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021016</td>\n",
       "      <td>0.022023</td>\n",
       "      <td>0.021718</td>\n",
       "      <td>0.019242</td>\n",
       "      <td>0.024655</td>\n",
       "      <td>0.022205</td>\n",
       "      <td>0.021145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025327</td>\n",
       "      <td>0.021708</td>\n",
       "      <td>0.022978</td>\n",
       "      <td>0.022685</td>\n",
       "      <td>0.015309</td>\n",
       "      <td>0.027855</td>\n",
       "      <td>0.022012</td>\n",
       "      <td>0.022364</td>\n",
       "      <td>0.022144</td>\n",
       "      <td>0.023015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018696</td>\n",
       "      <td>0.019112</td>\n",
       "      <td>0.021016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016296</td>\n",
       "      <td>0.016387</td>\n",
       "      <td>0.015976</td>\n",
       "      <td>0.018154</td>\n",
       "      <td>0.018167</td>\n",
       "      <td>0.017347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017680</td>\n",
       "      <td>0.016829</td>\n",
       "      <td>0.017739</td>\n",
       "      <td>0.017192</td>\n",
       "      <td>0.013695</td>\n",
       "      <td>0.018895</td>\n",
       "      <td>0.020322</td>\n",
       "      <td>0.019116</td>\n",
       "      <td>0.017161</td>\n",
       "      <td>0.019654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017525</td>\n",
       "      <td>0.018157</td>\n",
       "      <td>0.022023</td>\n",
       "      <td>0.016296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016917</td>\n",
       "      <td>0.015546</td>\n",
       "      <td>0.017945</td>\n",
       "      <td>0.017016</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018630</td>\n",
       "      <td>0.017159</td>\n",
       "      <td>0.017307</td>\n",
       "      <td>0.017516</td>\n",
       "      <td>0.013541</td>\n",
       "      <td>0.019418</td>\n",
       "      <td>0.016836</td>\n",
       "      <td>0.017001</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>0.017074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id     1         2         3         4         5         6         7      \\\n",
       "user_id                                                                         \n",
       "1        1.000000  0.019180  0.023084  0.018696  0.017525  0.017677  0.016032   \n",
       "2        0.019180  1.000000  0.024556  0.019112  0.018157  0.018160  0.016497   \n",
       "3        0.023084  0.024556  1.000000  0.021016  0.022023  0.021718  0.019242   \n",
       "4        0.018696  0.019112  0.021016  1.000000  0.016296  0.016387  0.015976   \n",
       "5        0.017525  0.018157  0.022023  0.016296  1.000000  0.016917  0.015546   \n",
       "\n",
       "user_id     8         9         10     ...     9991      9992      9993   \\\n",
       "user_id                                ...                                 \n",
       "1        0.019315  0.018985  0.018978  ...  0.019177  0.018299  0.019195   \n",
       "2        0.019604  0.019385  0.018334  ...  0.020182  0.018397  0.019344   \n",
       "3        0.024655  0.022205  0.021145  ...  0.025327  0.021708  0.022978   \n",
       "4        0.018154  0.018167  0.017347  ...  0.017680  0.016829  0.017739   \n",
       "5        0.017945  0.017016  0.016532  ...  0.018630  0.017159  0.017307   \n",
       "\n",
       "user_id     9994      9995      9996      9997      9998      9999      10000  \n",
       "user_id                                                                        \n",
       "1        0.019038  0.013683  0.020309  0.018878  0.019716  0.018796  0.019311  \n",
       "2        0.018800  0.014348  0.021568  0.019963  0.020066  0.018633  0.020665  \n",
       "3        0.022685  0.015309  0.027855  0.022012  0.022364  0.022144  0.023015  \n",
       "4        0.017192  0.013695  0.018895  0.020322  0.019116  0.017161  0.019654  \n",
       "5        0.017516  0.013541  0.019418  0.016836  0.017001  0.017115  0.017074  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 reacords in similarity matrix\n",
    "user_sim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get top-n recommendation for given user using User based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ubcf_ed(user_id, n_neighbors, top_n, user_sim):\n",
    "    '''\n",
    "    Description: function to get top_n number of book recommendations for given user_id\n",
    "    \n",
    "    Input:\n",
    "        user_id: The user of interest\n",
    "        n_neighbors: Number of neighbors for similarity count\n",
    "        top_n: Top n recommendations to return\n",
    "        similarity: The distance measure matrix between users\n",
    "    \n",
    "    Output: \n",
    "    The top n recommendations\n",
    "    '''\n",
    "    # Get the nearest neighbors\n",
    "    nearest_neighbors = user_sim[user_id].sort_values(ascending = False)[1:(n_neighbors+1)]\n",
    "    \n",
    "    # Obtain predicted ratings for unread books\n",
    "    unread_book_index = ratings.columns[ratings.loc[user_id] == 0]# get indexes of books unread by given user\n",
    "    missing_ratings = []\n",
    "    for book_id in unread_book_index:\n",
    "        neighbors_ratings = ratings.loc[nearest_neighbors.index, book_id]\n",
    "        missing_ratings.append(sum(nearest_neighbors * neighbors_ratings) / sum(nearest_neighbors))\n",
    "    \n",
    "    # Sort the predicted ratings in descending order \n",
    "    missing_ratings = pd.Series(missing_ratings, index=unread_book_index).sort_values(ascending = False)\n",
    "    \n",
    "    # Extract top n books\n",
    "    recommend_books = missing_ratings.index[:top_n]\n",
    "\n",
    "    ubcf_rec_book_title = []\n",
    "    #rec_book_rating_lst = []\n",
    "    # Print the recommendations\n",
    "    for i in range(top_n):\n",
    "        rec_book = recommend_books[i]\n",
    "        rec_book_title = merged_data[merged_data['book_id'] == rec_book]['original_title'].values[0]\n",
    "        rec_book_rating = missing_ratings.iloc[i]\n",
    "        print(\"Recommendation\", i+1, \"is\", rec_book_title , \n",
    "              \", with a predicted rating of\", round(missing_ratings.iloc[i],4))\n",
    "        \n",
    "        # store results for comparison\n",
    "        ubcf_rec_book_title.append(rec_book_title)\n",
    "    return ubcf_rec_book_title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation 1 is The Da Vinci Code , with a predicted rating of 1.5266\n",
      "Recommendation 2 is O Alquimista , with a predicted rating of 1.3822\n",
      "Recommendation 3 is Harry Potter and the Prisoner of Azkaban , with a predicted rating of 1.164\n",
      "Recommendation 4 is Harry Potter and the Philosopher's Stone , with a predicted rating of 1.154\n",
      "Recommendation 5 is Harry Potter and the Order of the Phoenix , with a predicted rating of 1.1414\n",
      "Recommendation 6 is The Kite Runner  , with a predicted rating of 1.0462\n",
      "Recommendation 7 is Harry Potter and the Goblet of Fire , with a predicted rating of 1.0238\n",
      "Recommendation 8 is Harry Potter and the Half-Blood Prince , with a predicted rating of 0.9846\n",
      "Recommendation 9 is Le Petit Prince , with a predicted rating of 0.9651\n",
      "Recommendation 10 is Harry Potter and the Chamber of Secrets , with a predicted rating of 0.9648\n",
      "Recommendation 11 is Angels & Demons  , with a predicted rating of 0.8677\n",
      "Recommendation 12 is Harry Potter and the Deathly Hallows , with a predicted rating of 0.8546\n",
      "Recommendation 13 is Nineteen Eighty-Four , with a predicted rating of 0.822\n",
      "Recommendation 14 is Animal Farm: A Fairy Story , with a predicted rating of 0.7933\n",
      "Recommendation 15 is Twilight , with a predicted rating of 0.727\n"
     ]
    }
   ],
   "source": [
    "# Call function with required details to get recommendations\n",
    "ubcf_rec_book_title = ubcf_ed(1839, 100, 15, user_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b. Item-Based Collaborative Filtering\n",
    "Next we will use item-based collaborative filtering. \n",
    "\n",
    "1. This time we will use cosine similarity to measure the similarity between items.\n",
    "2. Use 100 neighbors when calculating the predicted scores.\n",
    "3. Get the top 15 recommendations for user with user_id 1839. Get the book titles and predicted ratings.\n",
    "4. Also store the recommendations in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>book_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>9991</th>\n",
       "      <th>9992</th>\n",
       "      <th>9993</th>\n",
       "      <th>9994</th>\n",
       "      <th>9995</th>\n",
       "      <th>9996</th>\n",
       "      <th>9997</th>\n",
       "      <th>9998</th>\n",
       "      <th>9999</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.42632</td>\n",
       "      <td>0.469690</td>\n",
       "      <td>0.378218</td>\n",
       "      <td>0.34151</td>\n",
       "      <td>0.397019</td>\n",
       "      <td>0.294236</td>\n",
       "      <td>0.289858</td>\n",
       "      <td>0.325832</td>\n",
       "      <td>0.325946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016655</td>\n",
       "      <td>0.017877</td>\n",
       "      <td>0.02436</td>\n",
       "      <td>0.050888</td>\n",
       "      <td>0.037132</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>0.013394</td>\n",
       "      <td>0.057893</td>\n",
       "      <td>0.001413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.42632</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.486069</td>\n",
       "      <td>0.542027</td>\n",
       "      <td>0.45641</td>\n",
       "      <td>0.188067</td>\n",
       "      <td>0.511171</td>\n",
       "      <td>0.445516</td>\n",
       "      <td>0.445610</td>\n",
       "      <td>0.467768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01338</td>\n",
       "      <td>0.035157</td>\n",
       "      <td>0.032404</td>\n",
       "      <td>0.009075</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.028263</td>\n",
       "      <td>0.022892</td>\n",
       "      <td>0.030204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 9391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "book_id    1        2         3         4        5         6         7      \\\n",
       "book_id                                                                      \n",
       "1        1.00000  0.42632  0.469690  0.378218  0.34151  0.397019  0.294236   \n",
       "2        0.42632  1.00000  0.486069  0.542027  0.45641  0.188067  0.511171   \n",
       "\n",
       "book_id     8         9         10     ...     9991      9992     9993   \\\n",
       "book_id                                ...                                \n",
       "1        0.289858  0.325832  0.325946  ...  0.016655  0.017877  0.02436   \n",
       "2        0.445516  0.445610  0.467768  ...  0.024669  0.000000  0.01338   \n",
       "\n",
       "book_id     9994      9995      9996      9997      9998      9999      10000  \n",
       "book_id                                                                        \n",
       "1        0.050888  0.037132  0.012379  0.006301  0.013394  0.057893  0.001413  \n",
       "2        0.035157  0.032404  0.009075  0.005433  0.028263  0.022892  0.030204  \n",
       "\n",
       "[2 rows x 9391 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate books similarity\n",
    "books_sim = cosine_similarity(ratings.T)\n",
    "books_sim = pd.DataFrame(books_sim, index = ratings.columns, columns = ratings.columns)\n",
    "books_sim.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get top-n recommendation for given user using Item based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ibcf_cs(user_id, n_neighbors, top_n, books_sim):\n",
    "    '''\n",
    "    Description: function to get top_n number of book recommendations for given user_id\n",
    "    \n",
    "    Input:\n",
    "        user_id: The user of interest\n",
    "        n_neighbors: Number of neighbors for similarity count\n",
    "        top_n: Top n recommendations to return\n",
    "        books_sim: The similarity matrix\n",
    "    \n",
    "    Output: \n",
    "        The top n recommendations\n",
    "    '''\n",
    "    # Obtain unread book indices for given user_id\n",
    "    unread_book_index = ratings.columns[ratings.loc[user_id] == 0]\n",
    "    missing_ratings = []\n",
    "    \n",
    "    # Calculate predicted rating for each unread book\n",
    "    for book_id in unread_book_index:\n",
    "        nearest_neighbors = books_sim[book_id].sort_values(ascending = False)[1:(n_neighbors+1)]\n",
    "        neighbors_ratings = ratings.loc[user_id, nearest_neighbors.index]\n",
    "        missing_ratings.append(sum(nearest_neighbors * neighbors_ratings) / sum(nearest_neighbors))\n",
    "    \n",
    "    # Sort the predictions\n",
    "    missing_ratings = pd.Series(missing_ratings, index=unread_book_index).sort_values(ascending = False)\n",
    "    \n",
    "    # Extract only the top n books\n",
    "    recommend_books = missing_ratings.index[:top_n]\n",
    "    \n",
    "    ibcf_rec_book_title = []\n",
    "    \n",
    "    # Print the recommendations\n",
    "    for i in range(top_n):\n",
    "        rec_book = recommend_books[i]\n",
    "        rec_book_title = merged_data[merged_data['book_id'] == rec_book]['original_title'].values[0]\n",
    "        rec_book_rating = missing_ratings.iloc[i]\n",
    "        \n",
    "        print(\"recommendation \", i+1, \" is \", rec_book_title, \n",
    "              \", with a predicted rating of\", round(missing_ratings.iloc[i],4))\n",
    "\n",
    "        ibcf_rec_book_title.append(rec_book_title)\n",
    "    return ibcf_rec_book_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendation  1  is  Secret Prey , with a predicted rating of 1.1567\n",
      "recommendation  2  is  Sudden Prey , with a predicted rating of 1.1452\n",
      "recommendation  3  is  Night Prey , with a predicted rating of 1.1232\n",
      "recommendation  4  is  Mortal Prey , with a predicted rating of 1.1123\n",
      "recommendation  5  is  Mind Prey , with a predicted rating of 1.1096\n",
      "recommendation  6  is  Chosen Prey , with a predicted rating of 1.0448\n",
      "recommendation  7  is  Heat Lightning , with a predicted rating of 0.9576\n",
      "recommendation  8  is  Bad Blood , with a predicted rating of 0.8801\n",
      "recommendation  9  is  Shock Wave , with a predicted rating of 0.7435\n",
      "recommendation  10  is  The Graveyard Book , with a predicted rating of 0.7414\n",
      "recommendation  11  is  Abraham Lincoln: Vampire Hunter , with a predicted rating of 0.6799\n",
      "recommendation  12  is  Gathering Blue , with a predicted rating of 0.663\n",
      "recommendation  13  is  The Scorch Trials , with a predicted rating of 0.6533\n",
      "recommendation  14  is  Gathering Prey , with a predicted rating of 0.6511\n",
      "recommendation  15  is  Catching Fire , with a predicted rating of 0.6497\n"
     ]
    }
   ],
   "source": [
    "# Call function with required details to get recommendations\n",
    "ibcf_rec_book_title = ibcf_cs(1839, 100, 15, books_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.a. Matrix Factorization\n",
    "Now we will turn to model based methods. First we will look at Matrix Factorization. \n",
    "\n",
    "1. Use 3 latent factors.\n",
    "2. Set the learning rate at 0.001 and beta at 0.01. Since it will take a while to run, we will run only 5 iterations.\n",
    "3. Fit the model (it will take a while to run).\n",
    "4. Get the top 15 recommendations for user with user_id 1839. Return boths book names and predicted ratings.\n",
    "5. Store the recommendations in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(R, P, Q, K, steps=5, alpha=0.001, beta=0.01):\n",
    "    '''\n",
    "    Inputs:\n",
    "    R     : The ratings (of dimension M x N)\n",
    "    P     : an initial matrix of dimension M x K\n",
    "    Q     : an initial matrix of dimension N x K\n",
    "    K     : the number of latent features\n",
    "    steps : the maximum number of steps to perform the optimization\n",
    "    alpha : the learning rate\n",
    "    beta  : the regularization parameter\n",
    "\n",
    "    Outputs:\n",
    "    the final matrices P and Q\n",
    "    '''\n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(R.shape[0]):\n",
    "            for j in range(R.shape[1]):\n",
    "                if R[i][j] > 0: # Skipping over missing ratings\n",
    "                    eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                    for k in range(K):\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        eR = np.dot(P,Q)\n",
    "        e = 0\n",
    "        for i in range(R.shape[0]):\n",
    "            for j in range(R.shape[1]):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2)\n",
    "                    for k in range(K):\n",
    "                        e = e + (beta/2) * ( pow(P[i][k],2) + pow(Q[k][j],2) )\n",
    "        if e < 0.001: # tolerance\n",
    "            break\n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(862)\n",
    "\n",
    "# Initializations\n",
    "M = ratings.shape[0] # Number of users\n",
    "N = ratings.shape[1] # Number of books\n",
    "K = 3 # Number of latent features\n",
    "\n",
    "# Initial estimate of P and Q\n",
    "P = np.random.rand(M,K)\n",
    "Q = np.random.rand(K,N)\n",
    "rating_np = np.array(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model fitting. \n",
    "P, Q = matrix_factorization(rating_np, P, Q, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get decomposed rating matrix\n",
    "predicted_rating = np.matmul(P, Q)\n",
    "predicted_rating = pd.DataFrame(predicted_rating, index = ratings.index, columns = ratings.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendation  1  is  Jesus the Christ: A Study of the Messiah and His Mission according to Holy Scriptures both Ancient and Modern , with a predicted rating of 4.8311\n",
      "recommendation  2  is  The Essential Calvin and Hobbes: A Calvin and Hobbes Treasury , with a predicted rating of 4.752\n",
      "recommendation  3  is  Complete Harry Potter Boxed Set , with a predicted rating of 4.7015\n",
      "recommendation  4  is  The Brothers K , with a predicted rating of 4.6951\n",
      "recommendation  5  is  The Complete Anne of Green Gables Boxed Set , with a predicted rating of 4.6941\n",
      "recommendation  6  is  Maus II : And Here My Troubles Began  , with a predicted rating of 4.6793\n",
      "recommendation  7  is  Being Mortal: Medicine and What Matters in the End , with a predicted rating of 4.6703\n",
      "recommendation  8  is  Words of Radiance , with a predicted rating of 4.6588\n",
      "recommendation  9  is  The Complete Maus , with a predicted rating of 4.6473\n",
      "recommendation  10  is  The Authoritative Calvin and Hobbes , with a predicted rating of 4.6185\n",
      "recommendation  11  is  Calvin and Hobbes , with a predicted rating of 4.6087\n",
      "recommendation  12  is  The Hiding Place , with a predicted rating of 4.6024\n",
      "recommendation  13  is  Just Mercy: A Story of Justice and Redemption , with a predicted rating of 4.5997\n",
      "recommendation  14  is  The Hobbit and The Lord of the Rings , with a predicted rating of 4.5886\n",
      "recommendation  15  is  Left to Tell: Discovering God Amidst the Rwandan Holocaust , with a predicted rating of 4.5762\n"
     ]
    }
   ],
   "source": [
    "# get tp 15 recommendations for user_id = 1839\n",
    "select_ratings = predicted_rating.loc[1839].sort_values(ascending = False)[:15]\n",
    "recommend_books = select_ratings.index\n",
    "\n",
    "mf_rec_book_title=[]\n",
    "\n",
    "# Print the recommendations\n",
    "for i in range(15):\n",
    "    rec_book = recommend_books[i]\n",
    "    rec_book_title = merged_data[merged_data['book_id'] == rec_book]['original_title'].values[0]\n",
    "    print(\"recommendation \", i+1, \" is \", rec_book_title, \n",
    "          \", with a predicted rating of\", round(select_ratings.iloc[i],4))\n",
    "    mf_rec_book_title.append(rec_book_title)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b. SVD++\n",
    "\n",
    "First, we need to install the [surprise](http://surpriselib.com/) library.\n",
    "\n",
    "SVD++ is the factorization algorithm. However, the surprise library called it SVD instead (and use SVD++ for a different yet similar algorithm). Therefore our task here is to implement the [SVD](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD) algorithm from the surprise library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the surprise library, we need to first put the data into its accepted format. [Here](https://surprise.readthedocs.io/en/stable/getting_started.html#load-dom-dataframe-py) is an example on how it work. In general, we need to follow below steps:\n",
    "\n",
    "1. Set up a Reader class\n",
    "2. Load the dataframe \n",
    "3. Build the data set using the build_full_trainset() method (see [here](https://surprise.readthedocs.io/en/stable/trainset.html) or [here](https://stackoverflow.com/questions/49263964/datasetautofolds-object-has-no-attribute-global-mean-on-python-surprise))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set up the reader class\n",
    "reader = Reader(rating_scale=(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the dataframe. Use the merged data from above (not the pivoted data)\n",
    "data = Dataset.load_from_df(merged_data[['user_id', 'book_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build the train set\n",
    "svd_data = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have prepared the data set, next task is to build the model. The usage is similar to any sklearn model: first instantiate a model and set any hyperparamters, then but the model. For this model, use 5 latent factors, a learning rate of 0.01 for all parameters, and a regularization parameter of 0.1 for all parameters. We'll Set a random state to 862."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x11c5e3d68>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate SVD algorithm\n",
    "algo = SVD(n_factors=5, lr_all=0.01, reg_all= 0.1, random_state=862)\n",
    "algo.fit(svd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have fitted the model, we can perform prediction. There are several ways to do this:\n",
    "\n",
    "1. Calculate the individual ratings $r_{ui}$ by using the given equation [here](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD)\n",
    "2. Calculate the overall rating matrix by doing some matrix multiplications and manipulations\n",
    "3. Probably the easiest, is to use the predict function (see an example [here](https://surprise.readthedocs.io/en/stable/getting_started.html#predict-ratings2-py) and [here](https://predictivehacks.com/how-to-run-recommender-systems-in-python/). You may not need to use the str() function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the books that user with user_id 1839 have red from the list of suggested ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of the book ids\n",
    "unique_ids = merged_data['book_id'].unique()\n",
    "\n",
    "# get the list of the book ids that the userid 1839 has rated\n",
    "book_ids_1839 = merged_data.loc[merged_data['user_id']==1839, 'book_id']\n",
    "\n",
    "# remove the read books for the recommendations\n",
    "books_to_predict = np.setdiff1d(unique_ids,book_ids_1839)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendation  1  is  The Complete Calvin and Hobbes , with a predicted rating of 4.6455\n",
      "recommendation  2  is  دیوان‎‎ [Dīvān] , with a predicted rating of 4.617\n",
      "recommendation  3  is  I Want My Hat Back , with a predicted rating of 4.6018\n",
      "recommendation  4  is  Jesus the Christ: A Study of the Messiah and His Mission according to Holy Scriptures both Ancient and Modern , with a predicted rating of 4.593\n",
      "recommendation  5  is  The Sandman: King of Dreams , with a predicted rating of 4.5625\n",
      "recommendation  6  is  Preach My Gospel (A Guide to Missionary Service) , with a predicted rating of 4.5219\n",
      "recommendation  7  is   الرحيق المختوم: بحث في السيرة النبوية على صاحبها أفضل الصلاة والسلام  , with a predicted rating of 4.4992\n",
      "recommendation  8  is  There's Treasure Everywhere: A Calvin and Hobbes Collection , with a predicted rating of 4.4974\n",
      "recommendation  9  is  It's a Magical World: A Calvin and Hobbes Collection , with a predicted rating of 4.4843\n",
      "recommendation  10  is  Attack of the Deranged Mutant Killer Monster Snow Goons: A Calvin and Hobbes Collection , with a predicted rating of 4.4823\n",
      "recommendation  11  is  The Authoritative Calvin and Hobbes , with a predicted rating of 4.4796\n",
      "recommendation  12  is  The Days Are Just Packed: A Calvin and Hobbes Collection , with a predicted rating of 4.4789\n",
      "recommendation  13  is  Just Mercy: A Story of Justice and Redemption , with a predicted rating of 4.4735\n",
      "recommendation  14  is  Andy Goldsworthy: A Collaboration with Nature , with a predicted rating of 4.4652\n",
      "recommendation  15  is  The Hate U Give , with a predicted rating of 4.46\n"
     ]
    }
   ],
   "source": [
    "# get book recommendations for user 1839\n",
    "book_recs = []\n",
    "for book_id in books_to_predict:\n",
    "    rec_book_title = merged_data[merged_data['book_id'] == book_id]['original_title'].values[0]\n",
    "    book_recs.append((book_id, rec_book_title, algo.predict(uid=1839,iid=book_id).est))\n",
    "    \n",
    "user_rec = pd.DataFrame(book_recs, columns=['iid', 'book_title','predictions']).sort_values('predictions', ascending=False).head(15)\n",
    "\n",
    "# print top 15 book recommendations for user 1839\n",
    "svd_rec_book_title=[]\n",
    "for i in range(15):\n",
    "    print(\"recommendation \", i+1, \" is \", user_rec.iloc[i]['book_title'], \n",
    "          \", with a predicted rating of\", round(user_rec.iloc[i]['predictions'],4))\n",
    "    svd_rec_book_title.append(user_rec.iloc[i]['book_title'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "We have tried to provide recommendations to user 1839 using 4 methods. You last task is to put these 4 recommendations in a dataframe, with the column names the methods you used, and print out the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use as many boxes as you need.\n",
    "rec_comparison = pd.DataFrame(list(zip(ubcf_rec_book_title, ibcf_rec_book_title, mf_rec_book_title, svd_rec_book_title)),\n",
    "                                  columns=['User Based', 'Item Based', 'Matrix factorization', 'SVD matrix factorization'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Based</th>\n",
       "      <th>Item Based</th>\n",
       "      <th>Matrix factorization</th>\n",
       "      <th>SVD matrix factorization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Da Vinci Code</td>\n",
       "      <td>Secret Prey</td>\n",
       "      <td>Jesus the Christ: A Study of the Messiah and H...</td>\n",
       "      <td>The Complete Calvin and Hobbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O Alquimista</td>\n",
       "      <td>Sudden Prey</td>\n",
       "      <td>The Essential Calvin and Hobbes: A Calvin and ...</td>\n",
       "      <td>دیوان‎‎ [Dīvān]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>Night Prey</td>\n",
       "      <td>Complete Harry Potter Boxed Set</td>\n",
       "      <td>I Want My Hat Back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Mortal Prey</td>\n",
       "      <td>The Brothers K</td>\n",
       "      <td>Jesus the Christ: A Study of the Messiah and H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Mind Prey</td>\n",
       "      <td>The Complete Anne of Green Gables Boxed Set</td>\n",
       "      <td>The Sandman: King of Dreams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Kite Runner</td>\n",
       "      <td>Chosen Prey</td>\n",
       "      <td>Maus II : And Here My Troubles Began</td>\n",
       "      <td>Preach My Gospel (A Guide to Missionary Service)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Potter and the Goblet of Fire</td>\n",
       "      <td>Heat Lightning</td>\n",
       "      <td>Being Mortal: Medicine and What Matters in the...</td>\n",
       "      <td>الرحيق المختوم: بحث في السيرة النبوية على صاح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Harry Potter and the Half-Blood Prince</td>\n",
       "      <td>Bad Blood</td>\n",
       "      <td>Words of Radiance</td>\n",
       "      <td>There's Treasure Everywhere: A Calvin and Hobb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Le Petit Prince</td>\n",
       "      <td>Shock Wave</td>\n",
       "      <td>The Complete Maus</td>\n",
       "      <td>It's a Magical World: A Calvin and Hobbes Coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Harry Potter and the Chamber of Secrets</td>\n",
       "      <td>The Graveyard Book</td>\n",
       "      <td>The Authoritative Calvin and Hobbes</td>\n",
       "      <td>Attack of the Deranged Mutant Killer Monster S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Angels &amp; Demons</td>\n",
       "      <td>Abraham Lincoln: Vampire Hunter</td>\n",
       "      <td>Calvin and Hobbes</td>\n",
       "      <td>The Authoritative Calvin and Hobbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Gathering Blue</td>\n",
       "      <td>The Hiding Place</td>\n",
       "      <td>The Days Are Just Packed: A Calvin and Hobbes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nineteen Eighty-Four</td>\n",
       "      <td>The Scorch Trials</td>\n",
       "      <td>Just Mercy: A Story of Justice and Redemption</td>\n",
       "      <td>Just Mercy: A Story of Justice and Redemption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal Farm: A Fairy Story</td>\n",
       "      <td>Gathering Prey</td>\n",
       "      <td>The Hobbit and The Lord of the Rings</td>\n",
       "      <td>Andy Goldsworthy: A Collaboration with Nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>Catching Fire</td>\n",
       "      <td>Left to Tell: Discovering God Amidst the Rwand...</td>\n",
       "      <td>The Hate U Give</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   User Based  \\\n",
       "0                           The Da Vinci Code   \n",
       "1                                O Alquimista   \n",
       "2    Harry Potter and the Prisoner of Azkaban   \n",
       "3    Harry Potter and the Philosopher's Stone   \n",
       "4   Harry Potter and the Order of the Phoenix   \n",
       "5                            The Kite Runner    \n",
       "6         Harry Potter and the Goblet of Fire   \n",
       "7      Harry Potter and the Half-Blood Prince   \n",
       "8                             Le Petit Prince   \n",
       "9     Harry Potter and the Chamber of Secrets   \n",
       "10                           Angels & Demons    \n",
       "11       Harry Potter and the Deathly Hallows   \n",
       "12                       Nineteen Eighty-Four   \n",
       "13                 Animal Farm: A Fairy Story   \n",
       "14                                   Twilight   \n",
       "\n",
       "                         Item Based  \\\n",
       "0                       Secret Prey   \n",
       "1                       Sudden Prey   \n",
       "2                        Night Prey   \n",
       "3                       Mortal Prey   \n",
       "4                         Mind Prey   \n",
       "5                       Chosen Prey   \n",
       "6                    Heat Lightning   \n",
       "7                         Bad Blood   \n",
       "8                        Shock Wave   \n",
       "9                The Graveyard Book   \n",
       "10  Abraham Lincoln: Vampire Hunter   \n",
       "11                   Gathering Blue   \n",
       "12                The Scorch Trials   \n",
       "13                   Gathering Prey   \n",
       "14                    Catching Fire   \n",
       "\n",
       "                                 Matrix factorization  \\\n",
       "0   Jesus the Christ: A Study of the Messiah and H...   \n",
       "1   The Essential Calvin and Hobbes: A Calvin and ...   \n",
       "2                     Complete Harry Potter Boxed Set   \n",
       "3                                      The Brothers K   \n",
       "4         The Complete Anne of Green Gables Boxed Set   \n",
       "5               Maus II : And Here My Troubles Began    \n",
       "6   Being Mortal: Medicine and What Matters in the...   \n",
       "7                                   Words of Radiance   \n",
       "8                                   The Complete Maus   \n",
       "9                 The Authoritative Calvin and Hobbes   \n",
       "10                                  Calvin and Hobbes   \n",
       "11                                   The Hiding Place   \n",
       "12      Just Mercy: A Story of Justice and Redemption   \n",
       "13               The Hobbit and The Lord of the Rings   \n",
       "14  Left to Tell: Discovering God Amidst the Rwand...   \n",
       "\n",
       "                             SVD matrix factorization  \n",
       "0                      The Complete Calvin and Hobbes  \n",
       "1                                     دیوان‎‎ [Dīvān]  \n",
       "2                                  I Want My Hat Back  \n",
       "3   Jesus the Christ: A Study of the Messiah and H...  \n",
       "4                         The Sandman: King of Dreams  \n",
       "5    Preach My Gospel (A Guide to Missionary Service)  \n",
       "6    الرحيق المختوم: بحث في السيرة النبوية على صاح...  \n",
       "7   There's Treasure Everywhere: A Calvin and Hobb...  \n",
       "8   It's a Magical World: A Calvin and Hobbes Coll...  \n",
       "9   Attack of the Deranged Mutant Killer Monster S...  \n",
       "10                The Authoritative Calvin and Hobbes  \n",
       "11  The Days Are Just Packed: A Calvin and Hobbes ...  \n",
       "12      Just Mercy: A Story of Justice and Redemption  \n",
       "13      Andy Goldsworthy: A Collaboration with Nature  \n",
       "14                                    The Hate U Give  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the comparison of recommendations by memory based models, we can see that the books recommended by user based collaborative filtering and item based collaborative filtering are somewhat different. However, the comparison of recommendations using model based methods show that the results of matrix factorization and SVD matrix factorization are quite similar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
